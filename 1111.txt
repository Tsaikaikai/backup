# 方案1: 改善normalize函數，使用多種normalize策略

def improved_min_max_norm(image, method='adaptive'):
    """
    改善的normalize函數，支援多種策略
    """
    if method == 'adaptive':
        # 自適應normalize：根據異常點分布調整
        mean_val = np.mean(image)
        std_val = np.std(image)
        
        # 使用統計閾值而非絕對最值
        upper_threshold = mean_val + 2 * std_val
        lower_threshold = mean_val - 2 * std_val
        
        # 限制在統計範圍內
        image_clipped = np.clip(image, lower_threshold, upper_threshold)
        
        a_min, a_max = image_clipped.min(), image_clipped.max()
        if (a_min - a_max) == 0:
            return image * 0
        else:
            return (image - a_min) / (a_max - a_min)
    
    elif method == 'percentile':
        # 使用百分位數normalize，忽略極值
        p_low = np.percentile(image, 5)   # 第5百分位
        p_high = np.percentile(image, 95) # 第95百分位
        
        if (p_low - p_high) == 0:
            return image * 0
        else:
            return np.clip((image - p_low) / (p_high - p_low), 0, 1)
    
    elif method == 'sigmoid':
        # Sigmoid normalize，保持多個異常點的相對關係
        mean_val = np.mean(image)
        std_val = np.std(image)
        
        # 使用sigmoid函數
        normalized = 1 / (1 + np.exp(-(image - mean_val) / (std_val + 1e-8)))
        return normalized
    
    else:  # 原始方法
        a_min, a_max = image.min(), image.max()
        if (a_min - a_max) == 0:
            return image * 0
        else:
            return (image - a_min) / (a_max - a_min)

# 方案2: 多尺度異常融合策略
def multi_scale_anomaly_fusion(a_maps, fusion_method='weighted_sum'):
    """
    多尺度異常圖融合，更好地保留多個異常點
    """
    if fusion_method == 'weighted_sum':
        # 加權求和，不同尺度給不同權重
        weights = [0.3, 0.4, 0.3]  # 對應64x64, 32x32, 16x16
        anomaly_map = np.zeros_like(a_maps[0])
        
        for i, (a_map, weight) in enumerate(zip(a_maps, weights)):
            # 每個尺度先單獨normalize
            a_map_norm = improved_min_max_norm(a_map, method='percentile')
            anomaly_map += weight * a_map_norm
            
    elif fusion_method == 'max_pooling':
        # 取各尺度的最大值
        anomaly_map = np.zeros_like(a_maps[0])
        for a_map in a_maps:
            a_map_norm = improved_min_max_norm(a_map, method='percentile')
            anomaly_map = np.maximum(anomaly_map, a_map_norm)
            
    elif fusion_method == 'gaussian_weighted':
        # 高斯加權融合
        anomaly_map = np.zeros_like(a_maps[0])
        for i, a_map in enumerate(a_maps):
            a_map_norm = improved_min_max_norm(a_map, method='sigmoid')
            # 不同尺度使用不同的高斯權重
            sigma = 1.0 + i * 0.5
            weight = np.exp(-0.5 * (i / sigma) ** 2)
            anomaly_map += weight * a_map_norm
            
        # 最終normalize
        anomaly_map = improved_min_max_norm(anomaly_map, method='percentile')
        
    return anomaly_map

# 方案3: 改進的異常圖計算函數
def cal_anomaly_map_improved(fs_list, ft_list, out_size=224, fusion_method='gaussian_weighted'):
    """
    改進的異常圖計算，更好地處理多異常點
    """
    a_map_list = []
    
    # 先計算各尺度的異常圖
    for i in range(len(ft_list)):
        fs = fs_list[i]
        ft = ft_list[i]
        fs_norm = F.normalize(fs, p=2)
        ft_norm = F.normalize(ft, p=2)
        
        # 計算cosine距離
        a_map = 1 - cosine_similarity_onnx_exportable(fs_norm, ft_norm, 1)
        a_map = torch.unsqueeze(a_map, dim=1)
        a_map = F.interpolate(a_map, size=out_size, mode='bilinear', align_corners=False)
        a_map = a_map[0, 0, :, :].to('cpu').detach().numpy()
        a_map_list.append(a_map)
    
    # 使用改進的融合策略
    anomaly_map = multi_scale_anomaly_fusion(a_map_list, fusion_method)
    
    return anomaly_map, a_map_list

# 方案4: 自適應閾值處理
def adaptive_threshold_processing(anomaly_map, method='otsu'):
    """
    自適應閾值處理，更好地保留多個異常點
    """
    if method == 'otsu':
        # 使用Otsu閾值
        from skimage import filters
        threshold = filters.threshold_otsu(anomaly_map)
        binary_map = anomaly_map > threshold
        
        # 保留原始強度信息
        result = anomaly_map * binary_map
        
    elif method == 'multi_threshold':
        # 多級閾值
        thresholds = [0.3, 0.6, 0.9]  # 多個閾值等級
        result = np.zeros_like(anomaly_map)
        
        for i, thresh in enumerate(thresholds):
            mask = anomaly_map > thresh
            result += mask * (i + 1) * 0.25  # 不同等級給不同強度
            
        result = np.clip(result, 0, 1)
        
    elif method == 'local_maxima':
        # 局部最大值保留
        from skimage.feature import peak_local_maxima
        
        # 找局部最大值點
        local_maxima = peak_local_maxima(anomaly_map, min_distance=10, threshold_abs=0.1)
        
        # 創建增強後的異常圖
        result = anomaly_map.copy()
        for point in local_maxima:
            y, x = point
            # 增強局部最大值周圍區域
            result[max(0, y-5):min(result.shape[0], y+6), 
                   max(0, x-5):min(result.shape[1], x+6)] *= 1.5
                   
        result = np.clip(result, 0, 1)
        
    return result

# 方案5: 在測試階段的完整改進流程
def improved_test_processing(anomaly_map, a_maps, args):
    """
    改進的測試階段處理流程
    """
    # 使用改進的融合策略重新計算異常圖
    anomaly_map_improved = multi_scale_anomaly_fusion(a_maps, 'gaussian_weighted')
    
    # 自適應閾值處理
    anomaly_map_thresh = adaptive_threshold_processing(anomaly_map_improved, 'local_maxima')
    
    # 應用推理因子，但使用更溫和的方式
    inference_factor = args.inference_fator / 2  # 減少推理因子的影響
    anomaly_map_final = anomaly_map_thresh * inference_factor
    
    # 使用改進的normalize
    anomaly_map_norm = improved_min_max_norm(anomaly_map_final, method='percentile')
    
    # 進一步處理：保留多個異常區域
    anomaly_map_enhanced = enhance_multiple_anomalies(anomaly_map_norm)
    
    return anomaly_map_enhanced

# 修改原有的test函數中的處理部分
def modified_test_section():
    """
    這是您需要在train.py的test函數中替換的部分
    """
    # 原有代碼：
    # anomaly_map, a_maps = cal_anomaly_map(self.features_s, self.features_t, out_size=load_size)
    
    # 替換為：
    anomaly_map, a_maps = cal_anomaly_map_improved(self.features_s, self.features_t, 
                                                   out_size=load_size, 
                                                   fusion_method='gaussian_weighted')
    
    # 原有的normalize部分：
    # anomaly_map_norm = anomaly_map * args.inference_fator
    # anomaly_map_norm[anomaly_map_norm < 1] = 0
    # anomaly_map_norm = min_max_norm(anomaly_map_norm)
    
    # 替換為改進的處理：
    anomaly_map_norm = improved_test_processing(anomaly_map, a_maps, args)
    
    # 其餘處理保持不變
    anomaly_map_norm_hm = anomaly_map_norm * 255
    anomaly_map_norm_hm = center_crop(anomaly_map_norm_hm, oldsize)

def enhance_multiple_anomalies(anomaly_map, min_area=50):
    """
    增強多個異常區域的檢測
    """
    from skimage import measure, morphology
    
    # 二值化
    binary = anomaly_map > 0.3  # 較低的閾值保留更多異常點
    
    # 形態學處理
    binary = morphology.remove_small_objects(binary, min_size=min_area)
    binary = morphology.closing(binary, morphology.disk(3))
    
    # 找連通區域
    labeled = measure.label(binary)
    regions = measure.regionprops(labeled)
    
    # 為每個區域分配權重
    enhanced_map = np.zeros_like(anomaly_map)
    for region in regions:
        coords = region.coords
        # 根據區域大小和原始異常強度分配權重
        region_mask = labeled == region.label
        original_intensity = np.mean(anomaly_map[region_mask])
        area_weight = min(1.0, region.area / 1000)  # 面積權重
        
        # 組合權重
        final_weight = 0.7 * original_intensity + 0.3 * area_weight
        enhanced_map[region_mask] = final_weight
    
    return enhanced_map
